{"pageProps":{"posts":[{"slug":"graphql-partial-update","title":"GraphQL Partial Update","content":"\nRecently we decided to use [AWS Amplify](https://aws.amazon.com/amplify) for one of the products weâ€™re currently working on.\n\n[AWS Amplify](https://aws.amazon.com/amplify) promises to provide you with the option to rapidly develop the [REST](https://en.wikipedia.org/wiki/Representational_state_transfer) or a [GraphQL](https://graphql.org/) based backend that's very well integrated with your frontend development - be it a web application or a mobile app. That's at least the marketed value proposition.\n\nI don't wanna say that's [AWS Amplify](https://aws.amazon.com/amplify) is still in its infancy but let's say it's\nnot without its caveats. One of them is the documentation. In general AWS\nprovides a lot of documentation, which doesn't necessarily means that it's\ngood.\n\nUsually the truly technical documentation like the one for AWS SDK is really\ngood, which is not always the case with the Docs for other services. With AWS\nAmplify it's pretty often the case that the documentation is not up-to-date and\nyou have to dig through the GitHub tickets discussions to find the truth or\nthe undocumented features (yes, `@http resolvers` - I look at you)\n\nIf you have to provide custom headers to your HTTP resolver based GraphQL\noperation - you can send them as part of `API.graphql()` call as last\nparameter, e.g.\n\n```js\nconst headers = {\n  foor: 'bar',\n};\n\nconst response = await API.graphql(\n  graphqlOperation(createFooBar, { body }),\n  headers,\n);\n```\n\nBut I'm drifting away ðŸ˜€\n\nOk, so, we decided to go with GraphQL since in the final iterations the product should have more than just a web application and, theoretically, it should be easier to fetch only the data you need due to the flexible nature of [GraphQL](https://graphql.org/).\n\nSo, if you worked with [AWS Amplify](https://aws.amazon.com/amplify/) and [GraphQL](https://graphql.org/) you know that it doesnâ€™t support partial updates, which was a deal-breaker for us, since we have multiple flows where we have to partially push the data to the backend.\n\nAfter a short research online, I found a pretty cool article from [Arnaud BezanÃ§on](https://medium.com/@arnaud.bezancon) here [https://medium.com/workflowgen/graphql-mutations-partial-updates-implementation-bff586bda989](https://medium.com/workflowgen/graphql-mutations-partial-updates-implementation-bff586bda989)\n\nAlthough I really liked his way of doing things, my lazy nature wanted to have a more generic (not necessarily a better) solution though. So, my way of thinking was: since I only send parts of the data to the backend but it expects the whole { input } object from me, I will just merge the existing data with the new one and push it to the backend.\n\nWhat you have to consider as well is that you will have to remove any automatically generated/updated fields from your `json` object â€” in my case `createdAt/updatedAt` fields.\n\nSo, below you see a quick and dirty way of doing it.\n\nPlease, note that Iâ€™m using email as the key of our user model. In addition to that, you will have to always send the whole user object with all the fields to the update mutation â€” meaning when you call `getUser` it should fetch the user object with all the fields.\n\nIn a nutshell - the flow is the following:\n- try to fetch the user from the backend\n- if the user doesn't exist - call `createUser` with the provided data\n- if the user exist - merge the existing data with the new one and call\n  `updateUser`\n\n```js\nimport { API, graphqlOperation } from 'aws-amplify';\nimport { getUser } from '@/graphql/queries';\nimport { createUser, updateUser } from '@/graphql/mutations';\nimport { exclude } from '@/utils/json';\n\nconst get = async (email) => {\n  try {\n    const {\n      data: {\n        getUser: user,\n      },\n    } = await API.graphql(graphqlOperation(getUser, { email }));\n    return user;\n  } catch (error) {\n    throw new Error(error.errors);\n  }\n};\n\nconst createOrUpdate = async (input) => {\n  const { email } = input;\n  try {\n    const user = await get(email);\n    if (!user) {\n      await API.graphql(graphqlOperation(createUser, { input }));\n    } else {\n      // get current user data\n      // and only update the provided values\n      // createdAt, updatedAt have to be excluded\n      const update = { ...exclude(['createdAt', 'updatedAt'], user), ...input };\n      await API.graphql(graphqlOperation(updateUser, { input: update }));\n    }\n  } catch (error) {\n    throw new Error(error.errors);\n  }\n};\n\nexport {\n  get,\n  createOrUpdate,\n};\n```\n\nSince the email is used as the key of the user model, it has to be passed to the `createOrUpdate` function as part of the `{ input }` object. Whenever I have to create or update a user, we have to add the email to the input and then just call `createOrUpdate(input);`\n\n```js\nconst { email } = user;\nconst input = { email, â€¦payload };\n\ntry {\n  ...\n  await createOrUpdate(input);\n  ...\n} catch (error) {\n  throw new Error(error);\n}\n```\n\nItâ€™s not an efficient way of doing things since it will fetch the data from your backend before doing an update but this way you donâ€™t have to do things manually or thing about the values youâ€™d like to be updated.\n\nThatâ€™s all folks.\n","excerpt":"\nRecently we decided to use [AWS Amplify](https://aws.amazon.com/amplify) for one of the products weâ€™re currently working on.\n\n[AWS Amplify](https://aws.amazon.com/amplify) promises to provide you with the option to rapidly develop the [REST](https://en.wikipedia.org/wiki/Representational_state_transfer) or a [GraphQL](https://graphql.org/) based backend that's very well integrated with your frontend development - be it a web application or a mobile app. That's at least the marketed value proposition.\n"},{"slug":"mock-promisified-aws-sdk-calls","title":"Mock promisified AWS service operation calls with Jest","content":"\nAt [Mbanq Cloud](https://mbanq.com/cloud) we run most of our services on AWS and try to use AWS Lambda as much as possible.\n\nA while ago Iâ€™ve been working on the a small npm package that should have helped us to make use of SSM and [KMS](https://aws.amazon.com/kms/) to manage our system configuration. SSM and KMS play nicely together as the most of the AWS services.\n\nIn order to test the newly written npm package, I had to mock the promisified version of the `ssm.getParameters(request)`\n\n```js\nconst AWS = require('aws-sdk')\nconst ssm = AWS.SSM({ region: 'eu-west-1 })\nssm.getParameters(request).promise() // we have to mock the response from this call\n```\n\nThere are different ways of mocking the AWS JS SDK calls. For example there is the [aws-mock-sdk](https://github.com/dwyl/aws-sdk-mock) package from the very cool [DWYL](https://dwyl.com/) guys. I decided to go with pure Jest implementation though.\n\n![](https://cdn-images-1.medium.com/max/2000/1*yZyG4rhfvTehkTsKtLxD9Q.png)\n\nThere are some things to be taken into account to make the SSMâ€™s functionality testable:\n\n- Use **ssm** as a parameter in your function call, e.g. const `load = (ssm, keys, expiryMs)` It will help you to use the mocked ssm whenever you write your tests. Sure you could also `module.exports = { ssm }` alongside other functions you want to export but I didnâ€™t really like this idea\n- If you wanna check for the errors thrown inside of an `async/await` function you have to use: `expect(yourFunc()).rejects.toEqual(new Error('Error Message'))` . The regular `expect(yourFunc()).toThrowError('Error Message')` [**WONâ€™T WORK](https://github.com/facebook/jest/issues/1700#issuecomment-377890222)**\n\nOk, now youâ€™re probably asking yourself:\n> How the heck do you mock the promisified AWS service operation calls?\n\nYou will either want to mock a successful response from the `ssm.getParameters(request).promise()` or the `Error` thrown by the this function call.\n\n### Successful response\nFirst, create a js object with the promise key and mock the value of the promise with the `jest.fn().mockImplementation()` that will return a Promise that when resolved return a successful response.\n\nThen return the created `ssmPromise` whenever you make a call to `getParameters()` function.\n\n```js\nconst AWS = require('aws-sdk')\nlet ssm = new AWS.SSM()\nconst ssmPromise = {\n  promise: jest.fn().mockImplementation((request) => {\n    return new Promise((resolve, reject) => {\n      const response = {\n        Parameters: [\n          {\n            Name: 'bar',\n            Type: 'String',\n            Value: 'barfoorista',\n            Version: 1,\n            LastModifiedDate: '2018-08-22T13:49:55.717Z',\n            ARN: 'arn:aws:ssm:eu-west-1:whatever:parameter/bar'\n          },\n          {\n            Name: 'foo',\n            Type: 'String',\n            Value: 'foobarista',\n            Version: 1,\n            LastModifiedDate: '2018-08-22T13:49:41.486Z',\n            ARN: 'arn:aws:ssm:eu-west-1:whatever:parameter/foo'\n           }\n         ],\n         InvalidParameters: []\n       }\n       resolve(response)\n     })\n  })\n}\nssm = { getParameters: () => { return ssmPromise } }\n```\n\n### Throw an Error\n\nBy using the ssm instance you created at the top of your test, you can also mock the `ssm.getParameters()` in one go.\n\nHere is an example of how you could mock `ssm.getParameters()` throwing an Error\n\n```js\nssm = {\n  getParameters: () => {\n    return {\n      promise: jest.fn().mockImplementation((request) => {\n        return new Promise((resolve, reject) => {\n          return reject(new Error('foobar'))\n        }).catch(() => console.log('Ok'))\n      })\n    }\n  }\n}\n```\n\nIn a [gist](https://gist.github.com/igorkosta/6dae64ca2ababed7bec95255b2252842#file-sreda-test-js) (pun intended) you can see part of the test, weâ€™re using to test our package.\n\nHere is the content of the `gist` for you to check out:\n```js\n/* eslint-env jest */\n'use strict'\n\nconst { read, keys } = require('../sreda')\nconst AWS = require('aws-sdk')\nlet ssm = new AWS.SSM()\n\nvar ssmPromise = {\n  promise: jest.fn().mockImplementation((request) => {\n    return new Promise((resolve, reject) => {\n      const response = {\n        Parameters: [\n          {\n            Name: 'bar',\n            Type: 'String',\n            Value: 'barfoorista',\n            Version: 1,\n            LastModifiedDate: '2018-08-22T13:49:55.717Z',\n            ARN: 'arn:aws:ssm:eu-west-1:whatever:parameter/bar'\n          },\n          {\n            Name: 'foo',\n            Type: 'String',\n            Value: 'foobarista',\n            Version: 1,\n            LastModifiedDate: '2018-08-22T13:49:41.486Z',\n            ARN: 'arn:aws:ssm:eu-west-1:whatever:parameter/foo'\n          }\n        ],\n        InvalidParameters: []\n      }\n      resolve(response)\n    })\n  })\n}\nssm = { getParameters: () => { return ssmPromise } }\n\ndescribe('mock AWS.SSM()', () => {\n  beforeAll(async () => {\n    process.env.NODE_ENV = 'production'\n  })\n\n  it(`throws an error if no keys are providerd`, async () => {\n    function throwsErr () {\n      read(ssm, [])\n    }\n    expect(throwsErr).toThrowError(`You need to provide a non-empty array of config keys`)\n  })\n\n  it(`throws an error if some keys are missing`, async () => {\n    expect(keys(ssm, ['foobar'])).rejects.toEqual(new Error(`Missing SSM Parameter Store keys: foobar`))\n  })\n\n  it(`throws an error when ssm is throwing one`, async () => {\n    ssm = {\n      getParameters: () => {\n        return {\n          promise: jest.fn().mockImplementation((request) => {\n            return new Promise((resolve, reject) => {\n              return reject(new Error('foobar'))\n            }).catch(() => console.log('Ok'))\n          })\n        }\n      }\n    }\n    expect(keys(ssm, ['foo'])).rejects.toEqual(new Error(`TypeError: Cannot destructure property \\`Parameters\\` of 'undefined' or 'null'.`))\n  })\n})\n```\n\nThe `sreda` package is in the dev mode. Check it out if you would like to use\nit in you serverless project: https://www.npmjs.com/package/sreda\n\n```bash\nyarn add sreda\n\nnpm i -S sreda\n```\n","excerpt":"\nAt [Mbanq Cloud](https://mbanq.com/cloud) we run most of our services on AWS and try to use AWS Lambda as much as possible.\n\nA while ago Iâ€™ve been working on the a small npm package that should have helped us to make use of SSM and [KMS](https://aws.amazon.com/kms/) to manage our system configuration. SSM and KMS play nicely together as the most of the AWS services.\n"},{"slug":"vue-router","title":"Organize your routes with Vue Router","content":"Everyone has its own view on how to organize the routes in a Single-Page Application-weâ€™re not different.\n\nSince weâ€™re using [Vue.js](https://vuejs.org/) in our current project, weâ€™re also using the [Vue Router](https://router.vuejs.org/).\n\nHere I would like to describe the approach we took to organize our router and its routes. We will probably change/improve the current state later on but for now I will describe the [status quo](https://en.wikipedia.org/wiki/Status_quo).\n\n### Folder structure\n\nWe made a couple of iterations on how we want to organize our routes and we will definitely run through a couple of more iterations until weâ€™re fully satisfied.\n\n<div style=\"text-align: center;\">\n  <img src=\"https://cdn-images-1.medium.com/max/2704/1*Pj1ezbBzQnG4NHlD0seaWg.png\" width=\"400px\" />\n</div>\n\nCurrent folder structure we use is pretty straightforward:\n\n* `index.js`- defines the `beforeEach` logic for the routes\n\n* `/routes/public.js` â€” holds all the public routes (e.g. /, /login, /registration etc.)\n\n* `/routes/private.js` â€” has all the routes for the authenticated user\n\n* `/routes/index.js` - just concatenates all the public and private routes and exports them\n\nLetâ€™s walk quickly through every file â€” youâ€™ll see it will all make sense very quickly.\n\n### `src/router/index.js`\n\n`index.js` only holds one root route (you can also go without it). In our case itâ€™s the dashboard route, the user is redirected to once authenticated.\n\nOk, so the most important part of the `index.js` is the `beforeEach` check.\n\nIn our application we have two types of routes:\n\n* the strictly public ones â€” you have to be logged out to visit them\n\n* the private ones - you have to be authenticated to visit them\n\n```js\nimport Vue from 'vue'\nimport Router from 'vue-router'\nimport store from '@/store/index.js'\nimport routes from '@/router/routes/index.js'\nVue.use(Router)\n\nconst router = new Router({\n  routes: [\n    {\n      path: '/',\n      redirect: '/dashboard'\n    }\n  ].concat(routes)\n})\n\nrouter.beforeEach((to, from, next) => {\n  const authenticated = store.state.user.authenticated\n  const onlyLoggedOut = to.matched.some(record => record.meta.onlyLoggedOut)\n  const isPublic = to.matched.some(record => record.meta.public)\n  if (!isPublic && !authenticated) {\n    // this route requires auth, check if logged in\n    // if not, redirect to login page.\n    return next({\n      path: '/login',\n      query: { redirect: to.fullPath }\n    })\n  }\n  if (authenticated && onlyLoggedOut) {\n    return next('/')\n  }\n  next()\n})\n\nexport default router\n```\n\nAs you can see from the code snippet above, we read the authentication state from the local [Vuex](https://vuex.vuejs.org/) store. Other information that we need to decide whether a route can be visited or not is stored in the [meta field](https://router.vuejs.org/guide/advanced/meta.html) of the routes:\n\n* `onlyLoggedOut` â€” a route can only be visited by a non authenticated user\n\n* `isPublic` - itâ€™s a public route and can be visited without authentication (`/login`, `/registration` etc.)\n\nThere are only two cases (weâ€™d like to keep it simple in the beginning):\n\n* `!isPublic && !authenticated` â€” the user is not authenticated but is trying to access the private route â€” he/sheâ€™ll be redirected to the `/login` page and will be redirected to the page he was trying to access upon successful authentication\n\n* `authenticated && onlyLoggedOut` - the user is authenticated but is trying to access the public page â€” heâ€™ll be redirected back to the dashboard\n\n### `src/router/routes/public.js`\n\nWe were thinking about breaking down the routes and put every one of them into its own file, but, mmm-maybe later :).\n\nOk, so all the public routes are in one file and all of them rock the same meta field:\n\n```js\nmeta: {\n  public: true,\n  onlyLoggedOut: true\n}\n```\n\n```js\nimport Login from '@/views/Login.vue'\nimport Registration from '@/views/Registration.vue'\nimport ForgotPassword from '@/views/ForgotPassword.vue'\n\nconst routes = [\n  {\n    path: '/login',\n    name: 'login',\n    component: Login\n  },\n  {\n    path: '/registration',\n    name: 'registration',\n    component: Registration\n  },\n  {\n    path: '/forgot-password',\n    name: 'forgotPassword',\n    component: ForgotPassword\n  }\n]\n\nexport default routes.map(route => {\n  const meta = {\n    public: true,\n    onlyLoggedOut: true\n  }\n  return { ...route, meta }\n})\n```\n\nIn order to not pollute every route, weâ€™re adding the meta field to all the routes in the file in the export section. This way we donâ€™t have to think about adding the meta field to every new added route.\n\n### `src/router/routes/private.js`\n\nYou know the drill by now. All the private routes reside in one file and the meta field is added to each and one of them in the export section.\n\n```js\nimport Accounts from '@/views/Accounts/Index.vue'\nimport Dashboard from '@/views/Dashboard/Index.vue'\nimport Settings from '@/views/Settings/Index.vue'\n\nconst routes = [\n    {\n    path: '/accounts',\n    name: 'accounts',\n    component: Accounts\n  },\n  {\n    path: '/dashboard',\n    name: 'dashboard',\n    component: Dashboard\n  },\n  {\n    path: '/settings',\n    name: 'settings',\n    component: Settings\n  }\n]\n\nexport default routes.map(route => {\n  return { ...route, meta: { public: false } }\n})\n```\n\n### `src/router/routes/index.js`\n\nWhatâ€™s inside of the `routes/index.js` you may ask. Itâ€™s just the utility file that imports the routes from both `public.js` and `private.js` and exports them as one.\n\n```js\nimport publicRoutes from '@/router/routes/public.js'\nimport privateRoutes from '@/router/routes/private.js'\n\nexport default publicRoutes.concat(privateRoutes)\n```\n\nThis file is not necessary, you could just import public and private routes directly into the `src/router/index.js`\n\nThat's all folks!\n","excerpt":"Everyone has its own view on how to organize the routes in a Single-Page Application-weâ€™re not different.\n\nSince weâ€™re using [Vue.js](https://vuejs.org/) in our current project, weâ€™re also using the [Vue Router](https://router.vuejs.org/).\n\nHere I would like to describe the approach we took to organize our router and its routes. We will probably change/improve the current state later on but for now I will describe the [status quo](https://en.wikipedia.org/wiki/Status_quo)."}]},"__N_SSG":true}